{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mne\n",
    "%matplotlib qt\n",
    "from Globals import *\n",
    "PATH = '/Volumes/Media/毕业论文/实验2数据/pre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "418 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "420 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "313 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "312 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "372 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "368 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "322 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "323 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "421 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "421 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "367 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "386 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "392 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "405 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "411 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "413 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "344 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "385 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "365 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "405 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "382 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "386 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "314 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "349 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "415 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "414 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "372 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "361 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "Joe_1_evks_list = []\n",
    "Joe_2_evks_list = []\n",
    "Own_1_evks_list =[]\n",
    "Own_2_evks_list = []\n",
    "Other_1_evks_list = []\n",
    "Other_2_evks_list = []\n",
    "\n",
    "# read the data of every valid subject \n",
    "for sub in Sublist_exp2:\n",
    "    dir_name = 'Sub_0' + sub\n",
    "    dir_path = PATH + '/' + dir_name\n",
    "    os.chdir(dir_path)\n",
    "\n",
    "    ##### 确定分半类型  ######\n",
    "\n",
    "    first_epoch = mne.read_epochs('1_2_epochs_epo.fif', preload= True)\n",
    "    second_epoch = mne.read_epochs('2_2_epochs_epo.fif', preload= True)\n",
    "\n",
    "    # read each condition from each subject's data \n",
    "    Joe_1_epochs = first_epoch['JoeFace']\n",
    "    Own_1_epochs = first_epoch['OwnFace']\n",
    "    Other_1_epochs = first_epoch['OtherFace_1']\n",
    "\n",
    "    Joe_2_epochs = second_epoch['JoeFace']\n",
    "    Own_2_epochs = second_epoch['OwnFace']\n",
    "    Other_2_epochs = second_epoch['OtherFace_1']\n",
    "\n",
    "    # Calculate Evoke instance for each condition\n",
    "    Joe_1_evk = Joe_1_epochs.average()\n",
    "    Joe_2_evk = Joe_2_epochs.average()\n",
    "    Own_1_evk = Own_1_epochs.average()\n",
    "    Own_2_evk = Own_2_epochs.average()\n",
    "    Other_1_evk = Other_1_epochs.average()\n",
    "    Other_2_evk = Other_2_epochs.average()\n",
    "\n",
    "    # Append each subject's Evoke instance into a corresponding List\n",
    "    Joe_1_evks_list.append(Joe_1_evk)\n",
    "    Joe_2_evks_list.append(Joe_2_evk)\n",
    "    Own_1_evks_list.append(Own_1_evk)\n",
    "    Own_2_evks_list.append(Own_2_evk)\n",
    "    Other_1_evks_list.append(Other_1_evk)\n",
    "    Other_2_evks_list.append(Other_2_evk)\n",
    "    \n",
    "    # Save Evoke for each subject & each condietion\n",
    "    os.chdir('/Volumes/Media/毕业论文/实验二_分析/Half_Split/evks')\n",
    "    Joe_1_evk.save(sub + '_' + 'Joe_1_ave.fif')\n",
    "    Joe_2_evk.save(sub + '_' + 'Joe_2_ave.fif')\n",
    "    Own_1_evk.save(sub + '_' + 'Own_1_ave.fif')\n",
    "    Own_2_evk.save(sub + '_' + 'Own_2_ave.fif')\n",
    "    Other_1_evk.save(sub + '_' + 'Other_1_ave.fif')\n",
    "    Other_2_evk.save(sub + '_' + 'Other_2_ave.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n"
     ]
    }
   ],
   "source": [
    "# Calculate subjects' Grand Average for each condition\n",
    "\n",
    "Joe_1_grand_avg = mne.grand_average(Joe_1_evks_list) \n",
    "Joe_2_grand_avg = mne.grand_average(Joe_2_evks_list)\n",
    "Joe_1_grand_avg_df = Joe_1_grand_avg.to_data_frame()\n",
    "Joe_2_grand_avg_df = Joe_2_grand_avg.to_data_frame()\n",
    "Joe_compare_dict = dict(Joe_1 = Joe_1_grand_avg, Joe_2 = Joe_2_grand_avg)\n",
    "Joe_compare_dict = dict(Joe_1 = Joe_1_grand_avg, Joe_2 = Joe_2_grand_avg)\n",
    "picks = HEMISPHERES['left'] + HEMISPHERES['right']\n",
    "# Compare dict for the comparision of 1/3 vs. 2/3 or 1/2 vs. 2/2\n",
    "\n",
    "Own_1_grand_avg = mne.grand_average(Own_1_evks_list)\n",
    "Own_2_grand_avg = mne.grand_average(Own_2_evks_list)\n",
    "\n",
    "Other_1_grand_avg = mne.grand_average(Other_1_evks_list)\n",
    "Other_2_grand_avg = mne.grand_average(Other_2_evks_list)\n",
    "\n",
    "Own_compare_dict = dict(Own_1 = Own_1_grand_avg, Own_2 = Own_2_grand_avg)\n",
    "Other_compare_dict = dict(Other_1 = Other_1_grand_avg, Other_2 = Other_2_grand_avg)\n",
    "picks = HEMISPHERES['left'] + HEMISPHERES['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Volumes/Media/毕业论文/实验二_分析/Half_Split/evks_csv')\n",
    "Joe_1_grand_avg.to_data_frame().to_csv('Joe_1_grand_avg.csv')\n",
    "Joe_2_grand_avg.to_data_frame().to_csv('Joe_2_grand_avg.csv')\n",
    "Own_1_grand_avg.to_data_frame().to_csv('Own_1_grand_avg.csv')\n",
    "Own_2_grand_avg.to_data_frame().to_csv('Own_2_grand_avg.csv')\n",
    "Other_1_grand_avg.to_data_frame().to_csv('Other_1_grand_avg.csv')\n",
    "Other_2_grand_avg.to_data_frame().to_csv('Other_2_grand_avg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Volumes/Media/毕业论文/实验二_分析/Half_Split')\n",
    "Joe_1_grand_avg.save('Joe_1_grand_ave.fif')\n",
    "Joe_2_grand_avg.save('Joe_2_grand_ave.fif')\n",
    "Own_1_grand_avg.save('Own_1_grand_ave.fif')\n",
    "Own_2_grand_avg.save('Own_2_grand_ave.fif')\n",
    "Other_1_grand_avg.save('Other_1_grand_ave.fif')\n",
    "Other_2_grand_avg.save('Other_2_grand_ave.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ed695ad26f8d5f1293dce98a347c72fd779f35bb58c08f3d5c1f85f670c287e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
