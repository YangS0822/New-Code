{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib qt\n",
    "import mne\n",
    "from Globals import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "418 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "420 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "377 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "370 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "299 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "318 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "383 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "380 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "347 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "383 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "378 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "404 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 1_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "414 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading 2_2_epochs_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "414 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "# Export Evokes to Dataframe - .csv - for further analysis\n",
    "\n",
    "All_Sub_1_2_evks = {}\n",
    "All_Sub_2_2_evks = {}\n",
    "\n",
    "# Read epochs from two different parts. 1/2 vs. 2/2 or 1/3 vs. 2/3.\n",
    "for Sub in Sublist_exp2_excluded:\n",
    "    os.chdir('D:\\Onedrive\\\\毕业论文\\\\实验数据\\\\实验2数据\\\\pre\\\\Sub_0' + Sub)\n",
    "    epoch_1_2 = mne.read_epochs('1_2_epochs_epo.fif',preload=True)\n",
    "    epoch_2_2 = mne.read_epochs('2_2_epochs_epo.fif', preload=True)\n",
    "    evk_1_2 = {}\n",
    "    evk_2_2 = {}\n",
    "    for i in list(epoch_1_2.event_id.keys()):\n",
    "        evk_1_2[i]= epoch_1_2[i].average()\n",
    "        evk_2_2[i] = epoch_2_2[i].average()\n",
    "    All_Sub_1_2_evks[Sub] = evk_1_2\n",
    "    All_Sub_2_2_evks[Sub] = evk_2_2\n",
    "\n",
    "#condition evk : A dictionary includes dictionaries for each condition\n",
    "#               in each condition's dictionary, it includes all participants' data.\n",
    "condition_evk_1_2 = {}\n",
    "for cond in condition_list:\n",
    "    Ind_condition_evks = {}\n",
    "    for Sub in All_Sub_1_2_evks.keys():\n",
    "        Ind_evks = All_Sub_1_2_evks[Sub]\n",
    "        Ind_condition_evks[Sub] = Ind_evks[cond]\n",
    "    condition_evk_1_2[cond] = Ind_condition_evks\n",
    "\n",
    "\n",
    "condition_evk_2_2 = {}\n",
    "for cond in condition_list:\n",
    "    Ind_condition_evks = {}\n",
    "    for Sub in All_Sub_2_2_evks.keys():\n",
    "        Ind_evks = All_Sub_2_2_evks[Sub]\n",
    "        Ind_condition_evks[Sub] = Ind_evks[cond]\n",
    "    condition_evk_2_2[cond] = Ind_condition_evks\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\Onedrive\\\\毕业论文\\\\实验数据\\\\实验2数据\\\\pre\\\\evks_csv\\\\1_2')\n",
    "for cond in condition_evk_1_2.keys():\n",
    "    os.chdir('D:\\\\Onedrive\\\\毕业论文\\\\实验数据\\\\实验2数据\\\\pre\\\\evks_csv\\\\1_2')\n",
    "    os.mkdir(str(cond))\n",
    "    os.chdir(str(cond))\n",
    "    for sub in condition_evk_1_2[cond].keys():\n",
    "        per_evk = condition_evk_1_2[cond][sub]\n",
    "        per_evk =per_evk.to_data_frame()\n",
    "        per_evk.to_csv(str(sub) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\Onedrive\\\\毕业论文\\\\实验数据\\\\实验2数据\\\\pre\\\\evks_csv\\\\2_2')\n",
    "for cond in condition_evk_2_2.keys():\n",
    "    os.chdir('D:\\\\Onedrive\\\\毕业论文\\\\实验数据\\\\实验2数据\\\\pre\\\\evks_csv\\\\2_2')\n",
    "    os.mkdir(str(cond))\n",
    "    os.chdir(str(cond))\n",
    "    for sub in condition_evk_2_2[cond].keys():\n",
    "        per_evk = condition_evk_2_2[cond][sub]\n",
    "        per_evk =per_evk.to_data_frame()\n",
    "        per_evk.to_csv(str(sub) + '.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
